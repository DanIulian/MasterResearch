verbose: &verbose 1
name: "CuriosityRL"
title: "Proximal Policy Algorithm"
plots: "tensorboard" # can be "matplotlib", "tensorboard" or "both"

save_folder: "experiments"
save_interval: 100
log_interval: 10
eval_interval: 25

algo: "ppo"

training:
  num_env_steps: 40000000
  num_steps: 128
  num_processes: 16
  num_mini_batch: 64
  ppo_epoch: 4
  max_grad_norm: 0.5
  optimizer: Adam
  optimizer_args:
    lr: 0.0005
    eps: 0.00001

general:
  seed: 543
  cuda: yes
  use_linear_lr_decay: True
  use_linear_clip_decay: True
  use_clipped_value_loss: True

env:
  name: "BreakoutNoFrameskip-v4"
  add_timestep: False
  nr_frames: 4
  verbose: *verbose

agent:
  verbose: *verbose
  name: "PPOAgent"
  policy: "a3c_cnn"
  gamma: 0.99 #discount factor
  lam: 0.95 #gae parameter
  clip_param: 0.2
  target_kl: 0.2
  value_loss_coef: 0.5
  entropy_coef: 0.01
  use_initialization: True #use orthogonal initialization
  input_space: 4
